% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hme_glm.R
\name{hme}
\alias{hme}
\title{Hierarchical Mixture-of-Experts}
\usage{
hme(
  tree,
  formula,
  data,
  family = gaussian(),
  holdout = NULL,
  root_prior = 1,
  init_gate_pars = NULL,
  init_expert_pars = NULL,
  maxiter = 100,
  tolerance = 1e-04,
  trace = 0
)
}
\arguments{
\item{tree}{A character vector describing the structure of the gating network}

\item{formula}{A formula object in R describing the expert and network regressions.
The general structure is "y ~ x | z" where 'y' is the dependent variable, 'x'
the set of explanatory variables in the experts and 'z' is the set of variables
the gating network.}

\item{data}{The data.frame containing the variables y, x, and z}

\item{family}{The family of glm to use in the expert regressions}

\item{holdout}{An optional holdout set to track the mean squared error}

\item{root_prior}{deprecated}

\item{init_gate_pars}{A list (of lists) containing starting values for the gating parameters}

\item{init_expert_pars}{A list containing starting values for the expert regressions}

\item{maxiter}{The maximum number of iterations for the EM algorithm}

\item{trace}{Control how updates of the EM algorithm are printed to the console}

\item{tol}{Numeric indicating the convergence tolerance for the EM algorithm}
}
\value{
An object of class 'hme'
}
\description{
An R implementation of the HME model proposed by Jordan and Jacobs
}
